{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning.pytorch as pl\n",
    "import wandb\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "\n",
    "sys.path.append('/Users/ivan_zorin/Documents/DEV/code/ntl/')\n",
    "\n",
    "from models import *\n",
    "from data.data import SGCCDataset, sgcc_train_test_split\n",
    "from utils.utils import *\n",
    "\n",
    "from tqdm.auto import tqdm \n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan_zorin/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/lightning/pytorch/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# config and logger\n",
    "pathes_file = '../configs/local_pathes.yaml'\n",
    "config_path = '../configs/config.yaml'\n",
    "\n",
    "config = load_config(config_path, pathes_file)\n",
    "wandb_logger = WandbLogger(**config.logger) # TODO move this inside LightningModule\n",
    "# wandb.save(config_path) # save config file\n",
    "\n",
    "# random seed\n",
    "if config.seed is not None:\n",
    "    pl.seed_everything(config.seed, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ivan_zorin/Documents/DEV/runs/wandb/offline-run-20230602_114942-qrg7d6kc/files'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.run.dir # TODO use this to init tensorboard experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "train_data, val_data, test_data = sgcc_train_test_split(config)\n",
    "num_workers = config.num_workers\n",
    "train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "if config.supervised_validation:\n",
    "    val_loader = DataLoader(test_data, batch_size=config.batch_size, shuffle=False,  num_workers=num_workers)\n",
    "    \n",
    "else:\n",
    "    val_loader = DataLoader(val_data, batch_size=config.batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_data, batch_size=config.batch_size, shuffle=False,  num_workers=num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "nn_model = getattr(models, config.model)\n",
    "nn_model = nn_model(**config.model_kwargs)\n",
    "# Lightning model\n",
    "model = LitLSTMAE(\n",
    "    model=nn_model,\n",
    "    loss_fn=getattr(torch.nn.functional, config.loss),\n",
    "    optimizer=getattr(torch.optim, config.optimizer),\n",
    "    scheduler=getattr(torch.optim.lr_scheduler, config.scheduler),\n",
    "    config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = pl.Trainer(accelerator=config.device,\n",
    "                        logger=wandb_logger,\n",
    "                        \n",
    "                        **config.trainer_kwargs\n",
    "\n",
    "                        \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit loop\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test() if validation was unsupervised\n",
    "if not config.supervised_validation:\n",
    "    trainer.test(model, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload logs\n",
    "model.clear_mem()\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
