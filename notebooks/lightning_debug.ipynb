{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning.pytorch as pl\n",
    "import wandb\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "\n",
    "sys.path.append('/Users/ivan_zorin/Documents/DEV/code/ntl/')\n",
    "\n",
    "from models import *\n",
    "from data.data import SGCCDataset, sgcc_train_test_split\n",
    "from utils.utils import *\n",
    "\n",
    "from tqdm.auto import tqdm \n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(logger={'name': 'scheduler-test',\n",
       "                  'notes': 'drop samples with too many NaNs',\n",
       "                  'project': 'ntl',\n",
       "                  'offline': False,\n",
       "                  'save_dir': '/Users/ivan_zorin/Documents/DEV/runs/'},\n",
       "          seed=42,\n",
       "          trainer_kwargs={'fast_dev_run': False,\n",
       "                          'check_val_every_n_epoch': 1,\n",
       "                          'max_epochs': 20,\n",
       "                          'log_every_n_steps': 1,\n",
       "                          'limit_train_batches': None},\n",
       "          num_workers=2,\n",
       "          batch_size=32,\n",
       "          supervised_validation=True,\n",
       "          val_every_n_steps=5,\n",
       "          scale='minmax',\n",
       "          nan_ratio=0.6,\n",
       "          model='LSTMAE_old',\n",
       "          model_kwargs={'input_size': 1, 'hidden_size': [1024], 'n_lstms': 1},\n",
       "          loss='l1_loss',\n",
       "          optimizer='Adam',\n",
       "          optimizer_kwargs={'lr': 0.0001},\n",
       "          scheduler='ReduceLROnPlateau',\n",
       "          shcedule_kwargs={'factor': 0.5, 'patience': 3, 'verbose': True},\n",
       "          pca_dim=2,\n",
       "          ntl_wd='/Users/ivan_zorin/Documents/DEV/code/ntl/',\n",
       "          data_path='/Users/ivan_zorin/Documents/DEV/data/sgcc/data.csv',\n",
       "          save_dir='/Users/ivan_zorin/Documents/DEV/runs/',\n",
       "          device='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = load_config('../configs/config.yaml', '../configs/local_pathes.yaml')\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fast_dev_run': False,\n",
       " 'check_val_every_n_epoch': 1,\n",
       " 'max_epochs': 20,\n",
       " 'log_every_n_steps': 1,\n",
       " 'limit_train_batches': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.trainer_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 0jr3azbm.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(\n",
    "    name='first-run',\n",
    "    project='NTL',\n",
    "    config=config.__dict__,\n",
    "    offline=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync ./wandb/offline-run-20230530_111807-ymy7uu3v<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20230530_111807-ymy7uu3v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = sgcc_train_test_split(config)\n",
    "\n",
    "num_workers = 1\n",
    "train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_data, batch_size=config.batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_data, batch_size=config.batch_size, shuffle=False,  num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmae = LSTMAE_old(**config.model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitLSTMAE(\n",
    "    model=lstmae,\n",
    "    loss_fn=F.l1_loss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    config=config\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ivan_zorin/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(fast_dev_run=False,\n",
    "                     check_val_every_n_epoch=1,\n",
    "                     limit_train_batches=10,\n",
    "                     limit_val_batches=10,\n",
    "                     max_epochs=2,\n",
    "                    #  num_sanity_val_steps=1,\n",
    "                     accelerator=config.device,\n",
    "                    #  profiler='simple',\n",
    "                     logger=wandb_logger,\n",
    "                     log_every_n_steps=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
