{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# LOCAL\n",
    "# PROJECT_PATH = '/Users/ivan_zorin/Documents/DEV/code/ntl/'\n",
    "# DATA_PATH = '/Users/ivan_zorin/Documents/DEV/data/sgcc/data.csv'\n",
    "# LOG_DIR = '/Users/ivan_zorin/Documents/DEV/runs/debug/trainer'\n",
    "\n",
    "# ZHORES\n",
    "PROJECT_PATH = '/trinity/home/ivan.zorin/dev/code/ntl/'\n",
    "DATA_PATH = '/trinity/home/ivan.zorin/dev/data/sgcc/data.csv'\n",
    "LOG_DIR = '/trinity/home/ivan.zorin/dev/logs/debug/one-batch/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, robust_scale\n",
    "from sktime.transformations.series.impute import Imputer\n",
    "\n",
    "from functools import partial\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys\n",
    "sys.path.append(PROJECT_PATH)\n",
    "from ntl.data import SGCCDataset, data_train_test_split\n",
    "from ntl.data import FillNA, Scale, Reshape, ToTensor, Cutout\n",
    "from ntl.models import AE2dCNN\n",
    "from ntl.trainer import ArgsTrainer\n",
    "from ntl.utils import fix_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "fix_seed(42)\n",
    "\n",
    "transforms = [FillNA('drift'), \n",
    "            Cutout(256), \n",
    "            Scale('minmax'), \n",
    "            Reshape((16, 16)),\n",
    "            lambda x: x[None],\n",
    "            ToTensor()\n",
    "]\n",
    "normal_data = SGCCDataset(DATA_PATH, label=0, nan_ratio=0.75, transforms=transforms, year=2016)\n",
    "anomal_data = SGCCDataset(DATA_PATH, label=1, nan_ratio=1.0, transforms=transforms, year=2016)\n",
    "\n",
    "train, test = data_train_test_split(normal_data, anomal_data)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=64, drop_last=True, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one batch over-fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AE2dCNN()\n",
    "loss = nn.MSELoss(reduction='none')\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, factor=0.5, patience=2)\n",
    "logger = SummaryWriter(log_dir=LOG_DIR) \n",
    "\n",
    "config = SimpleNamespace(**{\n",
    "    'debug': True,\n",
    "    'n_debug_batches': 1,\n",
    "    'log_step': 5,\n",
    "    'n_epochs': 100\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan.zorin/.conda/pytorch/lib/python3.11/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = ArgsTrainer(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    model=model,\n",
    "    loss=loss,\n",
    "    optim=optim,\n",
    "    scheduler=scheduler,\n",
    "    config=config,\n",
    "    logger=logger\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check average values of normalized inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [FillNA('drift'), \n",
    "            Cutout(256), \n",
    "            Scale('minmax'), \n",
    "            # Reshape((16, 16)),\n",
    "            # lambda x: x[None],\n",
    "            # ToTensor()\n",
    "]\n",
    "normal_data = SGCCDataset(DATA_PATH, label=0, nan_ratio=0.75, transforms=transforms, year=2016)\n",
    "anomal_data = SGCCDataset(DATA_PATH, label=1, nan_ratio=1.0, transforms=transforms, year=2016)\n",
    "\n",
    "train, test = data_train_test_split(normal_data, anomal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values, min_values, mean_values, median_values = [], [], [], []\n",
    "for sample in tqdm(train):\n",
    "    x = sample[1]\n",
    "    max_values.append(x.max())\n",
    "    min_values.append(x.min())\n",
    "    mean_values.append(x.mean())\n",
    "    median_values.append(np.median(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(data, title=''):\n",
    "    plt.figure()\n",
    "    plt.hist(data, density=True)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_hist(max_values, 'max_values')\n",
    "# plot_hist(min_values, 'min_values')\n",
    "plot_hist(mean_values, 'mean_values')\n",
    "# plot_hist(median_values, 'median_values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "sample = train[idx][1]\n",
    "print(sample.mean())\n",
    "plt.plot(sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* normalize data to 0,1 scale | check\n",
    "* fill nans | check\n",
    "* cut-out some piece | check\n",
    "* reshape into matrix (7x52, square, other?) | check\n",
    "* use this matrix as input into AE | check\n",
    "\n",
    "\n",
    "Two ways of transformation \n",
    "The first one \n",
    "1. cut-out some piece\n",
    "2. fill na\n",
    "3. scale \n",
    "4. reshape\n",
    "\n",
    "The second one \n",
    "1. fill na\n",
    "2. scale\n",
    "3. cut-out some piece\n",
    "5. reshape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
